{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f35a728-f73f-4e78-a17d-6f49b535b103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                name  \\\n",
      "0  A Piece of Turkey Easy Roasted Thanksgiving Tu...   \n",
      "1                       Aarti Party aka Savory Sling   \n",
      "2                         Almost Famous Corn Pudding   \n",
      "3                                        a Great Pye   \n",
      "4                        Almost My Grandmas Rouladen   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.foodnetwork.com/recipes/jeff-mauro...   \n",
      "1  https://www.foodnetwork.com/recipes/aarti-part...   \n",
      "2  https://www.foodnetwork.com/recipes/michael-sy...   \n",
      "3  https://www.foodnetwork.com/recipes/a-great-py...   \n",
      "4  https://www.foodnetwork.com/recipes/melissa-da...   \n",
      "\n",
      "                                         ingredients  \n",
      "0  turkey, celery, yellow onion, rosemary, sage, ...  \n",
      "1  vodka, Zubrowka, Pineapple Reduction, pickling...  \n",
      "2  corn, boxes cornbread mix, eggs, corn kernels,...  \n",
      "3  shortcrust pastry, liquid, chicken breast, bee...  \n",
      "4  bacon, flatiron steak, ground pepper, Dijon mu...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of terms to exclude\n",
    "exclusions = [\n",
    "    \"halve\", \"halved\", \"lengthwise\", \"rough\", \"roughly\", \"chop\", \"chopped\", \"fresh\", \"freshly\", \n",
    "    \"crack\", \"cracked\", \"divide\", \"divided\", \"mince\", \"minced\", \"rinse\", \"rinsed\", \"dry\", \"dried\", \n",
    "    \"clean\", \"cleaned\", \"cut\", \"cutting\", \"slice\", \"sliced\", \"quarter\", \"quartered\", \"pack\", \n",
    "    \"packed\", \"beat\", \"beaten\", \"spray\", \"sprayed\", \"coarse\", \"coarsely\", \"medium\", \"fine\", \n",
    "    \"small\", \"large\", \"whole\", \"cup\", \"cups\", \"teaspoon\", \"teaspoons\", \"tablespoon\", \"tablespoons\", \n",
    "    \"pound\", \"pounds\", \"ounce\", \"ounces\", \"gram\", \"grams\", \"liter\", \"liters\", \"milliliter\", \n",
    "    \"milliliters\", \"clove\", \"cloves\", \"stick\", \"sticks\", \"package\", \"packages\", \"can\", \"cans\", \n",
    "    \"bottle\", \"bottles\", \"slice\", \"slices\", \"bulb\", \"bulbs\", \"finely\", \"medium-sized\", \"large-sized\", \n",
    "    \"small-sized\", \"extra-large\", \"extra-small\", \"half\", \"quarter\", \"third\", \"fourth\", \"fifth\", \n",
    "    \"sixth\", \"seventh\", \"eighth\", \"ninth\", \"tenth\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \n",
    "    \"10\", \"¼\", \"½\", \"¾\", \"⅛\", \"⅓\", \"⅔\", \"⅕\", \"⅖\", \"⅗\", \"⅘\", \"⅙\", \"⅚\", \"⅐\", \"⅛\", \"⅜\", \"⅝\", \n",
    "    \"⅞\", \"⅑\", \"⅒\", \"à\", \"á\", \"â\", \"ã\", \"ä\", \"å\", \"æ\", \"a\", \"dice\", \"diced\", \"crush\", \"crushed\", \"regular\", \"bundles\", \"bundle\"\n",
    "]\n",
    "\n",
    "# Simplified function to clean extracted entities\n",
    "def clean_text(text):\n",
    "    text = str(text)  # Ensure the text is a string\n",
    "    text = text.replace('\\xa0', ' ')  # Replace non-breaking space with a regular space\n",
    "    text = text.replace('xa0', '')    # Explicitly remove any occurrence of 'xa0'\n",
    "    text = re.sub(r'xa0', '', text)   # Remove any occurrence of 'xa0' in the text\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove any non-alphanumeric characters except for whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces and strip leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "# Define the ingredients to replace\n",
    "salt_variants = [\"salt\", \"kosher salt\", \"sea salt\"]\n",
    "pepper_variants = [\"black pepper\", \"pepper\"]\n",
    "oil_variants = [\"oil\", \"olive oil\", \"extra virgin olive oil\", \"extravirgin olive oil\", \"extravirginoliveoil\"]\n",
    "\n",
    "# Function to clean ingredients\n",
    "def clean_ingredients(ingredients):\n",
    "    ingredients_list = [ingredient.strip() for ingredient in ingredients.split(',')]\n",
    "    has_salt = any(ingredient in salt_variants for ingredient in ingredients_list)\n",
    "    has_pepper = any(ingredient in pepper_variants for ingredient in ingredients_list)\n",
    "    has_oil = any(ingredient in oil_variants for ingredient in ingredients_list)\n",
    "    \n",
    "    cleaned_ingredients = []\n",
    "    \n",
    "    for ingredient in ingredients_list:\n",
    "        if ingredient in salt_variants:\n",
    "            continue\n",
    "        if ingredient in pepper_variants:\n",
    "            continue\n",
    "        if ingredient in oil_variants:\n",
    "            continue\n",
    "        cleaned_ingredients.append(ingredient)\n",
    "    \n",
    "    if has_salt and has_pepper:\n",
    "        if has_oil:\n",
    "            cleaned_ingredients.append(\"SPO\")\n",
    "        else:\n",
    "            cleaned_ingredients.append(\"SP\")\n",
    "    elif has_oil:\n",
    "        cleaned_ingredients.append(\"O\")\n",
    "    \n",
    "    return ', '.join(cleaned_ingredients)\n",
    "\n",
    "# Function to exclude specific terms\n",
    "def exclude_terms(ents, exclusions):\n",
    "    return [ent for ent in ents if ent.lower() not in exclusions]\n",
    "\n",
    "# Function to display the results\n",
    "def display_results(names, urls, test_ingredients, nlp):\n",
    "    results = []\n",
    "    for name, url, ingredients in zip(names, urls, test_ingredients):\n",
    "        doc = nlp(ingredients)\n",
    "        # Exclude entities labeled as \"NON-ENTITY\"\n",
    "        extracted_ents = [clean_text(ent.text) for ent in doc.ents if ent.label_ != 'NON-ENTITY' and clean_text(ent.text)]\n",
    "        unique_ents = list(dict.fromkeys(extracted_ents))  # Remove duplicates while preserving order\n",
    "        unique_ents = exclude_terms(unique_ents, exclusions)  # Exclude terms from the list\n",
    "        cleaned_ingredients = clean_ingredients(', '.join(unique_ents))\n",
    "        results.append((clean_text(name), url, cleaned_ingredients))\n",
    "    \n",
    "    results_df = pd.DataFrame(results, columns=['name', 'url', 'ingredients'])\n",
    "    return results_df\n",
    "\n",
    "# Load your trained model directly from the specified path\n",
    "model_path = 'ner_model_test_class'\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model path '{model_path}' does not exist. Please check the path.\")\n",
    "\n",
    "nlp = spacy.load(model_path)\n",
    "\n",
    "# Path to your raw data file\n",
    "raw_data_path = '../Cleaned_Raw_Data/MASTERDATA1.csv'\n",
    "\n",
    "# Load the raw data\n",
    "df = pd.read_csv(raw_data_path)\n",
    "\n",
    "# Ensure all values in the ingredients column are strings and handle missing values\n",
    "df['ingredients'] = df['ingredients'].astype(str).fillna('')\n",
    "\n",
    "# Extract relevant columns\n",
    "names = df['name'].tolist()\n",
    "urls = df['url'].tolist()\n",
    "test_ingredients = df['ingredients'].tolist()\n",
    "\n",
    "# Display the results\n",
    "results_df = display_results(names, urls, test_ingredients, nlp)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(results_df.head())\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "output_filename = '../SpaCy_Extracted_Data/NER_Model_MASTERDATA_Class.csv'\n",
    "results_df.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7fb9a6-5876-4fa2-adeb-899a40cececd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged data saved to ../SpaCy_Extracted_Data/PINECONE_TAGGED_MASTERDATA_Class.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV data\n",
    "csv_file_path = '../SpaCy_Extracted_Data/NER_Model_MASTERDATA_Class.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Define the entity mapping function\n",
    "def tag_entities(ingredients):\n",
    "    if isinstance(ingredients, str):\n",
    "        ingredients_list = ingredients.split(', ')\n",
    "        tagged_ingredients = [{\"ingredient\": ing, \"entity\": \"ingredient\"} for ing in ingredients_list]\n",
    "        return tagged_ingredients\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Apply the entity tagging function to the ingredients column\n",
    "df['tagged_ingredients'] = df['ingredients'].apply(tag_entities)\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries\n",
    "records = df[['name', 'url', 'tagged_ingredients']].to_dict(orient='records')\n",
    "\n",
    "# Save the structured data to a JSON file\n",
    "json_file_path = '../SpaCy_Extracted_Data/PINECONE_TAGGED_MASTERDATA_Class.json'\n",
    "with open(json_file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Tagged data saved to {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3870b2-f16e-4ff4-9d87-a567da1ed08e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
